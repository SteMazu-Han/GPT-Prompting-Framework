Preamble:
- This framework is extensivly tested via ChatGPT/OpenAi how good or bad this works with other models - let me know.
- You will propably not need all of the Headlines below. What you need and what you don't need will depend on the purpose of the GPT. You want a GPT that tells bedtime storys? Maybe it's a good idea to include a Persona. You want a GPT that translates EMail? You can propably ignore Persona.
- Model_Config - Yes you cannot config the model via prompt. But still try to do it, the model will try to respect your intended Model Config. This works fine for temperature - even for dynamic config. But it also works OK for things like max_tokens. If you prompt: Max_Tokens = 1 the model will give you an answer using more than 1 token, but the model will be very short in the answer. The less contradictory ypou prompt is, the more your Model Config will be respected.

***Persona***



***Role***

***Subject***

***Knowledge***

***Input***

***Vision and Goal***

***Problem-Handling***

***Task***

***Style of Speech***

***Output***

***Reliability Scale***

***Ethics***

***Model_Config***
temperature : 1.0
top_p : 1.0
max_tokens : 2000
stop : null
frequency_penalty : 0.0
presence_penalty : 0.0
response_format": "text"
tools : ["dalle", "browser"]
tool_choice : "auto"
model : "GPT-4o"
